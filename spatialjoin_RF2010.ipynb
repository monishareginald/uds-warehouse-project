{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01eb2d86-05b2-4585-a3fc-307c3053b6f0",
   "metadata": {},
   "source": [
    "## Spatial Join Parcel/Scag to Census Data: 2010\n",
    "\n",
    "This notebook builds off of the \"test\" notebook, and will incorporate a spatial join to use Census data. For convenience this will be split into two notebooks, 2010 and 2020 data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1508fb-b9fc-4f08-9e99-f8843f8a5ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.inspection import PartialDependenceDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12240145-01b5-4020-bae6-7618a10926af",
   "metadata": {},
   "source": [
    "First we import and clean up the Parcel dataset that was created in LINK TO ALYSSA'S NOTEBOOK HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e56db94-4d11-4056-be13-7268e8983ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucyb\\AppData\\Local\\Temp\\ipykernel_14012\\2332676652.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  parcel_data=pd.read_csv('data/join_scag_to_parcels_left_2019.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APN</th>\n",
       "      <th>LAND_VALUE</th>\n",
       "      <th>distances</th>\n",
       "      <th>building_class</th>\n",
       "      <th>year</th>\n",
       "      <th>acres</th>\n",
       "      <th>sqft</th>\n",
       "      <th>num_warehouses</th>\n",
       "      <th>warehouse_2010</th>\n",
       "      <th>warehouse_2020</th>\n",
       "      <th>...</th>\n",
       "      <th>Specific Plan</th>\n",
       "      <th>Transportation, Communications, and Utilities</th>\n",
       "      <th>Under Construction</th>\n",
       "      <th>Undevelopable</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Vacant</th>\n",
       "      <th>Water</th>\n",
       "      <th>dollars_per_acre</th>\n",
       "      <th>county_Riverside</th>\n",
       "      <th>county_San Bernardino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>933260003.0</td>\n",
       "      <td>48418.0</td>\n",
       "      <td>38449.033944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2406.435207</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>933190003.0</td>\n",
       "      <td>210496.0</td>\n",
       "      <td>39355.337470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10667.570219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>933200001.0</td>\n",
       "      <td>347975.0</td>\n",
       "      <td>39133.409768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17690.981870</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>933180027.0</td>\n",
       "      <td>88468.0</td>\n",
       "      <td>39830.303362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9505.916138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>933180028.0</td>\n",
       "      <td>334555.0</td>\n",
       "      <td>38830.371787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16032.116147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           APN  LAND_VALUE     distances building_class  year  acres  sqft  \\\n",
       "0  933260003.0     48418.0  38449.033944            NaN   NaN    NaN   NaN   \n",
       "1  933190003.0    210496.0  39355.337470            NaN   NaN    NaN   NaN   \n",
       "2  933200001.0    347975.0  39133.409768            NaN   NaN    NaN   NaN   \n",
       "3  933180027.0     88468.0  39830.303362            NaN   NaN    NaN   NaN   \n",
       "4  933180028.0    334555.0  38830.371787            NaN   NaN    NaN   NaN   \n",
       "\n",
       "   num_warehouses  warehouse_2010  warehouse_2020  ...  Specific Plan  \\\n",
       "0             0.0               0               0  ...            0.0   \n",
       "1             0.0               0               0  ...            0.0   \n",
       "2             0.0               0               0  ...            0.0   \n",
       "3             0.0               0               0  ...            0.0   \n",
       "4             0.0               0               0  ...            0.0   \n",
       "\n",
       "   Transportation, Communications, and Utilities  Under Construction  \\\n",
       "0                                            0.0                 0.0   \n",
       "1                                            0.0                 0.0   \n",
       "2                                            0.0                 0.0   \n",
       "3                                            0.0                 0.0   \n",
       "4                                            0.0                 0.0   \n",
       "\n",
       "  Undevelopable  Unknown  Vacant Water dollars_per_acre  county_Riverside  \\\n",
       "0           0.0      0.0     0.0   0.0      2406.435207                 1   \n",
       "1           0.0      0.0     1.0   0.0     10667.570219                 1   \n",
       "2           0.0      0.0     1.0   0.0     17690.981870                 1   \n",
       "3           0.0      0.0     1.0   0.0      9505.916138                 1   \n",
       "4           0.0      0.0     0.0   0.0     16032.116147                 1   \n",
       "\n",
       "   county_San Bernardino  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in assessor-scag data\n",
    "parcel_data=pd.read_csv('data/join_scag_to_parcels_left_2019.csv')\n",
    "\n",
    "# data clean-up\n",
    "# use lambda functions to denote whether warehouse had been built on each parcel by 2010 and by 2020 (fixing error in previous version)\n",
    "parcel_data['warehouse_2010']=parcel_data.year.apply(lambda x: 1 if x<2010 else 0)\n",
    "parcel_data['warehouse_2020']=parcel_data.year.apply(lambda x: 1 if x<2020 else 0)\n",
    "parcel_data['built_2010s']=parcel_data.year.apply(lambda x: 1 if (2010 <= x < 2020) else 0)\n",
    "\n",
    "# replace county names w/ dummies\n",
    "dummies=pd.get_dummies(parcel_data.COUNTY, prefix='county')\n",
    "parcel_data = parcel_data.join(dummies)\n",
    "parcel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "debc1428-49e8-4ea2-a3e3-072cbe91c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning everything into float16 to save memory\n",
    "for col in parcel_data.columns:\n",
    "    if parcel_data[col].dtype == 'float64': # skip the string column (srprec)\n",
    "        parcel_data[col] = parcel_data[col].astype('float16')\n",
    "        \n",
    "#converting from int64 to int8\n",
    "for col in parcel_data.columns:\n",
    "    if parcel_data[col].dtype == 'int64': # skip the string column (srprec)\n",
    "        parcel_data[col] = parcel_data[col].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef5dd4c-a5a6-4f09-944e-a3a8cf7700d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in 2009 census data\n",
    "census09 = gpd.read_file('data/census_2009.gpkg')\n",
    "\n",
    "#census data isn't huge, but converting to float16 just to be safe\n",
    "for col in census09.columns:\n",
    "    if census09[col].dtype == 'float64': # skip the string column (srprec)\n",
    "        census09[col] = census09[col].astype('float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5975d8b-cf5f-4875-82ef-8b3f049da16c",
   "metadata": {},
   "source": [
    "#### First Join (index)\n",
    "Adding geometry back to Assessor/Scag df so we can do a spatial join to census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7200a-ec10-4b7d-8015-5a12f92edb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in parcel geometry to make assessor/scag df into a Gdf \n",
    "parcels_geometry = gpd.read_file('data/parcels_warehouses.gpkg', include_fields=['APN', 'geometry'])\n",
    "\n",
    "#make APN into float16\n",
    "parcels_geometry.APN = parcels_geometry.APN.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f441b-d7fd-4d00-ae0c-59d6febe1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop old geometry column in scag/assessor data. Note: tried using the wkt method, couldn't get it to work :(\n",
    "parcel_data = parcel_data.drop('geometry', axis = 1)\n",
    "\n",
    "#joining geometry back to scag/assessor data\n",
    "parcel_data_geo = parcel_data.join(parcels_geometry.set_index('APN'), on = 'APN', how = 'left').reset_index()\n",
    "#making it back into a GDF\n",
    "parcel_data_geo = gpd.GeoDataFrame(parcel_data_geo, geometry = 'geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2b64c9-d2e7-4fa8-a826-7d4ff0476f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning all int64 into int8 for our Gdf\n",
    "for col in parcel_data_geo.columns:\n",
    "    if parcel_data_geo[col].dtype == 'int64': # skip the string column (srprec)\n",
    "        parcel_data_geo[col] = parcel_data_geo[col].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53807811-ebd0-4d16-9ffa-a50783855faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parcel_data_geo.to_file('data/parcel_scag_geo.gpkg', driver = 'gpkg') <- eventually may need this for next notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733db5f3-0005-4f4a-8295-7d02f6a44aed",
   "metadata": {},
   "source": [
    "Now, create a dataset to represent the conditions in the Inland Empire in 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689af3a-9c17-4b01-a55e-662060af4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new df for just 2010\n",
    "parceldata_10=parcel_data_geo.copy()\n",
    "#memory conversions\n",
    "for col in parceldata_10.columns:\n",
    "    if parceldata_10[col].dtype == 'float32': # skip the string column (srprec)\n",
    "        parceldata_10[col] = parceldata_10[col].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f8adc-1540-4c7a-9106-649bd2ad3f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy dataset and delete/rename variables as needed\n",
    "parceldata_10.drop(columns=['warehouse_2020'],inplace=True)\n",
    "parceldata_10.rename(columns={'warehouse_2010':'warehouse_start','built_2010s':'buit_within_decade'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212fa62-0c75-471a-8c1c-d489896b6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimenting with memory dtypes\n",
    "for col in parcelcensus10.columns:\n",
    "    if parcelcensus10[col].dtype == 'float32': # skip the string column (srprec)\n",
    "        parcelcensus10[col] = parcelcensus10[col].astype('float16')\n",
    "for col in parcelcensus10.columns:\n",
    "    if parcelcensus10[col].dtype == 'float64': # skip the string column (srprec)\n",
    "        parcelcensus10[col] = parcelcensus10[col].astype('float16')\n",
    "parcelcensus10.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8946c-c9cb-4b5c-8f02-c2acedebff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spatial join to just the 2010 census data, use CA Zone 5\n",
    "parceldata_10 = parceldata_10.to_crs(2229)\n",
    "census09 = census09.to_crs(2229)\n",
    "parcelcensus10 = gpd.sjoin(parceldata_10, census09, how = 'left', predicate='intersects')\n",
    "\n",
    "# need to set APN to be index so that we can join this back to other information later on\n",
    "parcelcensus10.set_index('APN',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530b47a-ad47-4658-823a-ff208c3d34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimenting with memory dtypes\n",
    "for col in parcelcensus10.columns:\n",
    "    if parcelcensus10[col].dtype == 'int64': # skip the string column (srprec)\n",
    "        parcelcensus10[col] = parcelcensus10[col].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaee275-a257-4dd4-a63f-ef8b458cba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parcelcensus10.to_file('parcelcensus10.gpkg', driver = 'gpkg') <- eventually may need this for next notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f7c305-ed05-4d00-9020-fabffb90726a",
   "metadata": {},
   "source": [
    "### Train model with 2010 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d7fb2-9de4-4d5a-a7ac-ce9ffd4846f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables \n",
    "cols=parcelcensus10.columns.to_list()\n",
    "xvars=[col for col in cols if col not in ('APN','building_class','year','acres','sqft','num_warehouses','buit_within_decade',\n",
    "                                          'geometry','PID19','APN19','CITY','COUNTY','LU19','LU16','JURISDICTI','LU19_CLASS','SCAG_ZN_CO','NAME',\n",
    "                                          'Shape_Leng','Shape_Area')]\n",
    "yvar = 'buit_within_decade'\n",
    "\n",
    "# create a dataframe with no NaNs\n",
    "parceldata_10_model = parcelcensus10[xvars+[yvar]].dropna()\n",
    "\n",
    "# create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    parceldata_10_model[xvars], parceldata_10_model[yvar], test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d5f45-7869-4af5-aa04-a112a8d05e21",
   "metadata": {},
   "source": [
    "Now we run the model and use it to make predictions with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689f5ab-43d0-4443-ab71-e8351f5df1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the random forest classifer object\n",
    "rf = RandomForestClassifier(n_estimators = 10, random_state = 1)\n",
    "\n",
    "# fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# apply predictions to test dataset\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247f65c-c429-4da9-9731-0ccdefb7a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop if the length of the predictions doesn't match the training dataset\n",
    "assert len(X_test)==len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f23aa5-098d-48a5-b8cd-234d5afc7fb2",
   "metadata": {},
   "source": [
    "We used a Confusion Matrix for an initial assessment of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ace55-4633-4603-80b2-4a043d456e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted fraction True: {:.4f}. Actual fraction True: {:.4f}'.format(\n",
    "    y_pred.mean(), y_test.mean()))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55881575-59fd-49a6-8cc8-85d0a2714b84",
   "metadata": {},
   "source": [
    "We used the feature importances to identify variables worth looking into further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c26b72-ce5b-4c2a-bd23-1c8443b72afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create series of importances\n",
    "importances = rf.feature_importances_\n",
    "forest_importances = pd.Series(importances, index=X_train.columns)\n",
    "forest_importances.sort_values(inplace=True, ascending=False)\n",
    "\n",
    "# plot them\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "sns.barplot(x=forest_importances[:15].values, y=forest_importances[:15].index, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6975fb85-ed66-43f2-9083-a3829b82a415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
